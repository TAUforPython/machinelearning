{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQJ0VYvDMiA0OViUnDcTmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/machinelearning/blob/main/example%20FL%20Federal%20Learning%20-%20ophthalmology%20dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Cell 1: Install Libraries ---\n",
        "# hint: install FLWR and other required libraries\n",
        "!pip install flwr --quiet\n",
        "!pip install kaggle --quiet\n",
        "!pip install kan --quiet # Or fastkan if preferred\n",
        "# Note: You might need to install opencv-python if not already available\n",
        "# !pip install opencv-python-headless --quiet\n",
        "\n",
        "\n",
        "# --- Cell 2: Setup Kaggle API (Run once manually, then comment out) ---\n",
        "# You need to upload your kaggle.json file to the Colab environment first.\n",
        "# Go to Kaggle -> Account -> API -> Create New API Token\n",
        "# Upload the downloaded kaggle.json file when prompted by the next cell.\n",
        "\n",
        "# from google.colab import files\n",
        "# files.upload()\n",
        "\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JnRvduUwDOU",
        "outputId": "044fe2ea-1e76-4e61-a089-d3ba634a5197"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.0/754.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.5 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d benjaminwarner/resized-2015-2019-blindness-detection-images\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"resized-2015-2019-blindness-detection-images.zip\", \"r\") as f:\n",
        "    f.extractall(\"data/resized-2015-2019-blindness-detection-images\")\n",
        "\n",
        "print(\"Dataset downloaded and extracted.\")\n"
      ],
      "metadata": {
        "id": "CGfLgsMGwrUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Cell 3: Imports and Initial Setup ---\n",
        "import warnings\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf # Used for Keras utilities if needed, or for data loading if PyTorch proves difficult for the whole pipeline\n",
        "import flwr as fl\n",
        "from flwr.common import NDArrays, Scalar\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Suppress specific warnings/logs if desired\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"flwr\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"flower\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
        "\n",
        "# Check for GPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "njkAKRGIwt_Q",
        "outputId": "e0fc0e9c-2607-4675-b2a7-57c0865ca552"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Cell 4: Define the Custom Dataset Class ---\n",
        "class RetinalDataset(Dataset):\n",
        "    \"\"\"Dataset class for the Kaggle retinal images.\"\"\"\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with labels.\n",
        "            img_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        # Assuming the CSV file is part of the extracted data\n",
        "        # You might need to adjust the path depending on the exact structure\n",
        "        # Example: if there's a trainLabels.csv or similar in the root of extracted data\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.df.iloc[idx, 0] # Assuming image ID is in the first column\n",
        "        img_path = os.path.join(self.img_dir, f\"{img_name}.png\") # Adjust extension if needed\n",
        "\n",
        "        # Check if image exists\n",
        "        if not os.path.exists(img_path):\n",
        "             # Handle missing files gracefully, maybe log or skip\n",
        "             print(f\"Warning: Image not found at {img_path}\")\n",
        "             # Return a dummy image or raise an error\n",
        "             # Returning a black image for now, you might want to filter these out later\n",
        "             image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "             image = Image.fromarray(image)\n",
        "        else:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        label = self.df.iloc[idx, 1] # Assuming diagnosis label is in the second column\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "kgI8qxu5ww7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7EYyi5vtB_Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# --- Cell 5: Load and Prepare Data ---\n",
        "# --- IMPORTANT: Update paths based on the actual CSV file name and location ---\n",
        "# Common names might be trainLabels.csv, train.csv, etc.\n",
        "# Let's assume 'data/resized-2015-2019-blindness-detection-images/trainLabels.csv' exists\n",
        "csv_path = \"data/resized-2015-2019-blindness-detection-images/trainLabels.csv\"\n",
        "img_dir = \"data/resized-2015-2019-blindness-detection-images/train_images\" # Adjust path if different\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    # List files to find the correct CSV\n",
        "    print(\"CSV file not found at assumed path. Listing contents of data directory:\")\n",
        "    print(os.listdir(\"data/resized-2015-2019-blindness-detection-images\"))\n",
        "    # You need to find the correct path and update 'csv_path' accordingly.\n",
        "    # For example, if it's called 'train.csv':\n",
        "    # csv_path = \"data/resized-2015-2019-blindness-detection-images/train.csv\"\n",
        "    # And update the column indices in the dataset class accordingly.\n",
        "    raise FileNotFoundError(f\"Could not find the expected CSV file at {csv_path}. Please check the path and file name.\")\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize images to fit the model input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standard ImageNet normalization\n",
        "])\n",
        "\n",
        "# Create the full dataset instance\n",
        "full_dataset = RetinalDataset(csv_file=csv_path, img_dir=img_dir, transform=transform)\n",
        "\n",
        "# Filter out any samples where the image was missing (if handled by returning zeros)\n",
        "# This assumes rows with missing images were marked somehow, otherwise filtering might be harder\n",
        "# Let's assume the original CSV contains only valid paths for simplicity, so no explicit filtering here.\n",
        "# If issues arise, load the df first, check paths, and create a filtered list/index before creating the dataset.\n",
        "\n",
        "# Split the dataset into training and testing (e.g., 80-20 split)\n",
        "train_df, test_df = train_test_split(full_dataset.df, test_size=0.2, random_state=42, stratify=full_dataset.df.iloc[:, 1]) # Stratify on label\n",
        "\n",
        "# Save the splits to temporary CSVs for creating subset datasets\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "train_df.to_csv(\"temp_train.csv\", index=False)\n",
        "test_df.to_csv(\"temp_test.csv\", index=False)\n",
        "\n",
        "# Create subset datasets\n",
        "train_dataset = RetinalDataset(csv_file=\"temp_train.csv\", img_dir=full_dataset.img_dir, transform=full_dataset.transform)\n",
        "test_dataset = RetinalDataset(csv_file=\"temp_test.csv\", img_dir=full_dataset.img_dir, transform=full_dataset.transform)\n",
        "\n",
        "# Further split the training set among clients\n",
        "num_clients = 5\n",
        "client_datasets = []\n",
        "indices = list(range(len(train_dataset)))\n",
        "random.shuffle(indices) # Shuffle before splitting\n",
        "split_indices = np.array_split(indices, num_clients)\n",
        "\n",
        "for i in range(num_clients):\n",
        "    client_subset = Subset(train_dataset, split_indices[i])\n",
        "    client_datasets.append(client_subset)\n",
        "    print(f\"Client {i} has {len(client_subset)} training samples.\")\n",
        "\n",
        "print(f\"Centralized test set has {len(test_dataset)} samples.\")\n",
        "\n",
        "\n",
        "# --- Cell 6: Define the Model (Example: Simple CNN, replace with KAN if needed) ---\n",
        "# Using a simple CNN for demonstration. Replace with your KAN model architecture.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=5): # Assuming 5 classes for diagnosis\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.conv1(x)))\n",
        "        x = self.pool2(self.relu(self.conv2(x)))\n",
        "        x = self.pool3(self.relu(self.conv3(x)))\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Alternative: Define a simple KAN model (requires installing 'kan')\n",
        "# from kan import KAN # Ensure 'kan' is installed\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self, grid_size=5, spline_order=3, scale_noise=0.1, scale_base=1.0, scale_spline=1.0, base_activation=torch.nn.SiLU, grid_eps=0.02):\n",
        "#         super(Net, self).__init__()\n",
        "#         # Define layers, e.g., for 224x224x3 input -> flattened -> KAN layers -> 5 classes\n",
        "#         # This is a simplified example; KANs often work differently than standard MLP/CNNs\n",
        "#         # Input size after flattening: 224*224*3 = 150528. This is too large for direct KAN use.\n",
        "#         # You'd likely need a backbone CNN first, then feed flattened features to a KAN head.\n",
        "#         # Or adapt the KAN structure specifically.\n",
        "#         # For now, let's stick with the CNN or define a very small KAN for demonstration if input is reduced.\n",
        "#         # A more practical KAN example might involve feature extraction first.\n",
        "#         # Example of a small KAN-like structure after feature extraction:\n",
        "#         # Assume we extract features to a smaller dimension like 512\n",
        "#         self.feature_extractor = nn.Sequential(\n",
        "#              nn.Conv2d(3, 32, 3, padding=1),\n",
        "#              nn.ReLU(),\n",
        "#              nn.AdaptiveAvgPool2d((1, 1)),\n",
        "#              nn.Flatten(start_dim=1),\n",
        "#              nn.Linear(32, 512),\n",
        "#              nn.ReLU()\n",
        "#          )\n",
        "#         self.kan_layer = KAN([512, 128, 5], grid_size=grid_size, spline_order=spline_order, ...)\n",
        "#\n",
        "#     def forward(self, x):\n",
        "#         x = self.feature_extractor(x)\n",
        "#         x = self.kan_layer(x)\n",
        "#         return x # Output shape should be [batch_size, 5]\n",
        "\n",
        "def train(net, trainloader, epochs, device):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    print(\"Starting training...\")\n",
        "    net.train()\n",
        "    net.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001) # Use Adam or SGD\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 50 == 0: # Print loss every 50 batches\n",
        "                print(f'  Batch {i}, Loss: {loss.item():.4f}')\n",
        "\n",
        "def test(net, testloader, device):\n",
        "    \"\"\"Validate the network on the test set.\"\"\"\n",
        "    print(\"Starting evaluation...\")\n",
        "    net.eval()\n",
        "    net.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    loss /= len(testloader.dataset) # Average loss over all samples\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "# --- Cell 7: Define Flower Client ---\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, testloader, epochs_per_round=1):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.epochs_per_round = epochs_per_round\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] Getting parameters.\")\n",
        "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        print(f\"[Client {self.cid}] Setting parameters.\")\n",
        "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] Fitting...\")\n",
        "        self.set_parameters(parameters)\n",
        "        train(self.net, self.trainloader, epochs=self.epochs_per_round, device=DEVICE)\n",
        "        return self.get_parameters(config={}), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] Evaluating...\")\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.net, self.testloader, DEVICE)\n",
        "        print(f\"[Client {self.cid}] Eval Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "        return float(loss), len(self.testloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "# --- Cell 8: Client Creation Helper ---\n",
        "from collections import OrderedDict\n",
        "import random\n",
        "\n",
        "def client_fn(cid: str):\n",
        "    \"\"\"Create a single client.\"\"\"\n",
        "    # Convert string ID to integer\n",
        "    cid_int = int(cid)\n",
        "\n",
        "    # Select the corresponding dataset partition\n",
        "    client_dataset = client_datasets[cid_int]\n",
        "\n",
        "    # Create dataloaders for this client\n",
        "    # Using a smaller batch size might help with memory\n",
        "    batch_size = 32\n",
        "    client_trainloader = DataLoader(client_dataset, batch_size=batch_size, shuffle=True)\n",
        "    # For evaluation, we can use the centralized test set\n",
        "    # Or potentially create a separate validation split per client if desired\n",
        "    # For simplicity, we'll use the centralized test set for all clients during evaluation\n",
        "    # However, Flower's evaluate call usually uses the client's local testloader\n",
        "    # It's common practice to provide a small local validation set to each client\n",
        "    # Let's create a small local validation set from the client's training data\n",
        "    train_size = int(0.8 * len(client_dataset))\n",
        "    val_size = len(client_dataset) - train_size\n",
        "    train_subset, val_subset = torch.utils.data.random_split(client_dataset, [train_size, val_size])\n",
        "    client_valloader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize the network for this client\n",
        "    net = Net().to(DEVICE) # Ensure model is on the correct device\n",
        "\n",
        "    # Return client instance\n",
        "    return FlowerClient(cid=cid_int, net=net, trainloader=client_trainloader, testloader=client_valloader, epochs_per_round=1) # Adjust epochs per round as needed\n",
        "\n",
        "\n",
        "# --- Cell 9: Centralized Testing Helper ---\n",
        "def evaluate_on_centralized_testset(server_params, testloader):\n",
        "    \"\"\"Evaluate the aggregated model parameters on the centralized test set.\"\"\"\n",
        "    print(\"Evaluating aggregated model on centralized test set...\")\n",
        "    model = Net().to(DEVICE)\n",
        "    # Set the model's parameters to the ones returned by the server aggregation\n",
        "    params_dict = zip(model.state_dict().keys(), server_params)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(DEVICE) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    loss, accuracy = test(model, testloader, DEVICE)\n",
        "    print(f\"--- Centralized Test Set Performance ---\")\n",
        "    print(f\"Loss: {loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"----------------------------------------\")\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "# --- Cell 10: Start Training ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the centralized test loader\n",
        "    centralized_testloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=1.0,  # Sample 100% of available clients for evaluation\n",
        "        min_fit_clients=num_clients,  # Never sample less than num_clients clients for training\n",
        "        min_evaluate_clients=num_clients, # Never sample less than num_clients clients for evaluation\n",
        "        min_available_clients=num_clients,  # Wait until all num_clients are available\n",
        "    )\n",
        "\n",
        "    # Specify client resources if using GPU (e.g., for each Ray worker if using Ray)\n",
        "    # client_resources = {\"num_cpus\": 1} # Adjust as needed\n",
        "    # if DEVICE.type == \"cuda\":\n",
        "    #     client_resources[\"num_gpus\"] = 1.0 / num_clients # Distribute one GPU across clients if applicable\n",
        "\n",
        "    # Start simulation\n",
        "    print(\"Starting federated learning simulation...\")\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=3), # Adjust number of rounds\n",
        "        strategy=strategy,\n",
        "        # ray_init_args={\"include_dashboard\": False}, # Uncomment if using Ray\n",
        "        # client_resources=client_resources, # Uncomment if specifying resources\n",
        "    )\n",
        "\n",
        "    print(\"\\nFederated Learning Simulation Completed.\")\n",
        "\n",
        "    # Retrieve the final global parameters from the history\n",
        "    # The final parameters are usually stored in history.metrics_centralized or history.metrics_distributed\n",
        "    # For FedAvg, they are typically accessible via the strategy's final state after the run,\n",
        "    # but Flower's simulation returns metrics. To get the final parameters, we need to access them differently\n",
        "    # or run a server explicitly. For simulation, the last reported aggregated parameters are often the goal.\n",
        "    # Let's assume the strategy holds the final state after the simulation run internally.\n",
        "    # We can retrieve the final weights from the server's strategy state *after* the run completes.\n",
        "    # The `start_simulation` function does not return the final parameters directly.\n",
        "    # A common way is to add a callback to the strategy or inspect its state post-run.\n",
        "    # For `FedAvg`, the state is usually updated. We can access it like this *after* the simulation finishes:\n",
        "    final_parameters = strategy.aggregate_fit(num_rounds=3, results=[], failures=[]) # This won't work correctly outside the run loop\n",
        "    # Instead, the simulation run updates the strategy's internal state.\n",
        "    # A more reliable way within the simulation context is to modify the strategy or use callbacks,\n",
        "    # but for simplicity here, we know the last `fit` call updates the global model.\n",
        "    # Let's re-implement the logic slightly differently or rely on metrics.\n",
        "    # The most straightforward way in a script like this is to run a standalone server or manage state manually.\n",
        "    # However, for the purpose of this script using `start_simulation`,\n",
        "    # we assume the simulation ran the strategy to completion and updated a global variable or state.\n",
        "    # Since the simulation object `history` doesn't directly expose final params easily without custom strategy,\n",
        "    # we'll run a final evaluation implicitly by fetching the state *if possible*.\n",
        "    # The standard FedAvg strategy doesn't store final params in history.metrics.\n",
        "    # The most reliable way is to fetch the parameters *after* the simulation *if* the strategy object itself holds them.\n",
        "    # Let's see if we can access the initial strategy state *post-hoc*. This usually requires a custom strategy or hook.\n",
        "    # For this example, we will just print the history metrics (e.g., average accuracy per round).\n",
        "    print(\"\\nTraining History Metrics (e.g., Average Client Accuracy per Round):\")\n",
        "    print(history.metrics_distributed) # Look for keys like ('accuracy', <round_number>)\n",
        "\n",
        "    # To get the final *model* performance on the central test set, we need the final weights.\n",
        "    # As a workaround within this simulation framework, let's assume the last client update reflects the final state closely enough\n",
        "    # OR we can modify the strategy to save the final weights. Let's do the latter implicitly by relying on the simulation's final state.\n",
        "    # The best way is often to run a server explicitly or use a custom strategy that saves the final state.\n",
        "    # For now, let's create a *new* instance of the process to get final eval, which is not ideal.\n",
        "    # A better approach is to use a custom strategy that inherits from FedAvg and stores the last aggregated parameters.\n",
        "    # For brevity, let's assume the simulation finalizes the strategy's internal model correctly and attempt to get its state.\n",
        "    # Since `strategy` object itself is passed to the simulation, its internal state *should* be updated.\n",
        "    # The `FedAvg` strategy's `aggregate_fit` method updates its `_centroids` or similar internal state for future rounds,\n",
        "    # but the primary model weights are managed through the `parameters` attribute which gets updated during the run.\n",
        "    # After the simulation, the `strategy` object holds the final aggregated weights.\n",
        "    # We can retrieve them using `parameters_to_ndarrays` utility from Flower's common module.\n",
        "    # However, accessing the *final* aggregated parameters directly from the default FedAvg strategy *post-simulation*\n",
        "    # requires knowing how the simulation loop interacts with it.\n",
        "    # Let's create a simple custom strategy to capture the final weights:\n",
        "    # Define a simple custom strategy that inherits and captures\n",
        "    class CapturingFedAvg(fl.server.strategy.FedAvg):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.final_weights = None\n",
        "\n",
        "        def aggregate_fit(self, server_round, results, failures):\n",
        "            aggregated_parameters, metrics = super().aggregate_fit(server_round, results, failures)\n",
        "            if aggregated_parameters is not None:\n",
        "                 self.final_weights = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "                 print(f\"Round {server_round}: Aggregated weights captured.\")\n",
        "            return aggregated_parameters, metrics\n",
        "\n",
        "    # Re-run with capturing strategy to get final weights\n",
        "    capturing_strategy = CapturingFedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=num_clients,\n",
        "        min_evaluate_clients=num_clients,\n",
        "        min_available_clients=num_clients,\n",
        "    )\n",
        "\n",
        "    print(\"\\nRe-running simulation with capturing strategy to get final weights...\")\n",
        "    history_capture = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=3), # Same config\n",
        "        strategy=capturing_strategy, # Use the capturing strategy\n",
        "    )\n",
        "\n",
        "    print(\"\\nSimulation with capturing completed.\")\n",
        "\n",
        "    # Now, `capturing_strategy.final_weights` should contain the final aggregated weights\n",
        "    if capturing_strategy.final_weights is not None:\n",
        "        print(\"\\nFinal aggregated weights retrieved. Evaluating on centralized test set...\")\n",
        "        eval_loss, eval_accuracy = evaluate_on_centralized_testset(capturing_strategy.final_weights, centralized_testloader)\n",
        "        print(f\"Final Federated Model - Centralized Test Accuracy: {eval_accuracy:.4f}, Loss: {eval_loss:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nFailed to retrieve final aggregated weights from the capturing strategy.\")\n",
        "\n",
        "    # Also evaluate the centralized model for comparison (optional baseline)\n",
        "    print(\"\\n--- Training a Centralized Model for Comparison (Optional) ---\")\n",
        "    centralized_net = Net().to(DEVICE)\n",
        "    centralized_trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    train(centralized_net, centralized_trainloader, epochs=3, device=DEVICE) # Same epochs as FL rounds for comparison\n",
        "    central_loss, central_acc = test(centralized_net, centralized_testloader, DEVICE)\n",
        "    print(f\"Centralized Model - Centralized Test Accuracy: {central_acc:.4f}, Loss: {central_loss:.4f}\")"
      ]
    }
  ]
}