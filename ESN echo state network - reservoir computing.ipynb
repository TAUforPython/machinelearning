{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/machinelearning/blob/main/ESN%20echo%20state%20network%20-%20reservoir%20computing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDNcxiYS5m_D"
      },
      "source": [
        "# Neural networks : Echo State Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/RomainPastureau/Reservoir-Jupyter/blob/master/Minimal%20ESN%20-%20EN.ipynb"
      ],
      "metadata": {
        "id": "jseu2ghm6aUm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzJF6Gu75m_E"
      },
      "source": [
        "## A brief introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqyzVgZi5m_F"
      },
      "source": [
        "<p style=\"text-align:justify\">Since Frank Rosenblatt first created the perceptron in 1957, numerous neural models have surfaced. An <i>echo state network</i> is a Recurrent Neural Network (i.e., where the path may not be linear, allowing the network to have a memory) whose reservoir contains randomly generated neurons. Only the output weights (between the reservoir and the output) can be modified, through supervised learning : we can compare the network output to a « target » output. In this notebook, we will focus on an ESN model developped by Mantas Lukoševičius.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BJ5TfB1-5m_F"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydVdNnMg5m_G"
      },
      "source": [
        "## Module importation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kc651lN5m_G"
      },
      "source": [
        "We'll first import the modules we need. We will need the <i>%matplotlib inline</i> command, which allows to plot graphs directly into the notebook, and the modules <b>numpy</b> (numerical module allowing vectors and matrix handling), <b>matplotlib</b> (which will plot graphs), <b>scipy</b> (whose linalg method will allow the importation of linear algebra functions), and <b>IPython</b> widgets, allowing to interact in real time with the graphs by moving cursors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ttAeb7z5m_G"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "A minimalistic Echo State Networks demo with Mackey-Glass (delay 17) data\n",
        "in \"plain\" scientific Python.\n",
        "by Mantas Lukoševičius 2012\n",
        "http://minds.jacobs-university.de/mantas\n",
        "---\n",
        "Modified by Xavier Hinaut: 2015-2016\n",
        "http://www.xavierhinaut.com\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import linalg\n",
        "from ipywidgets import *\n",
        "from IPython.display import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDk66VH65m_H"
      },
      "source": [
        "## Random reset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkyrMORB5m_I"
      },
      "source": [
        "We will initiate a first pseudo-random value, depending on the current time when launching the algorithm. This will allow to ensure that two different launchs of the program will not give the same results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6U9Lvv75m_I"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=None):\n",
        "    \"\"\"Making the seed (for random values) variable if None\"\"\"\n",
        "\n",
        "    if seed is None:\n",
        "        import time\n",
        "        seed = int((time.time()*10**6) % 4294967295)\n",
        "        print(seed)\n",
        "    try:\n",
        "        np.random.seed(seed)\n",
        "        print(\"Seed used for random values:\", seed)\n",
        "    except:\n",
        "        print(\"!!! WARNING !!!: Seed was not set correctly.\")\n",
        "    return seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lac6LAS55m_I"
      },
      "source": [
        "## Creating a \"Network\" class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7UwjFSY5m_I"
      },
      "source": [
        "We create a <i>Network</i> class. When initialized, an object from this class will have 4 default attributes :\n",
        "\n",
        "<ul><li><b>initLen</b> : number of initializing iterations. During this phase, nothing happens: this allows to start the training with an intermediate value, rather than one of the first given values;;</li>\n",
        "<li><b>trainLen</b> : number of training iterations. The network changes the weights between the reservoir and the output, so that it can predict or generate a series;</li>\n",
        "<li><b>testLen</b> : number of testing iterations;</li>\n",
        "<li><b>data</b> : data file. Here, the file contains the first 10'000 iterations of a Mackey-Glass chaotic series. A chaotic series is a series of numbers provided by a function, for which a small alteration of the origin number can have drastic consequences on the following terms.</li></ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9irUoo5m_J"
      },
      "source": [
        "The default number of neurons contained in the reservoir is 300 (<b>resSize</b>), while the input and the output contain both one neuron (<b>inSize and outSize</b>). The network can be represented like this : <img src=\"Reservoir.png\"></img>\n",
        "\n",
        "<p style=\"text-align:justify\">Input neurons are connected to reservoir neurons. We save the weights of every connection in a <b style=\"color:#99cc00\">W<sub>in</sub></b> matrix (dim. inSize x resSize). Weights of the connections from reservoir to the output are saved in the <b style=\"color:#ff0000\">W<sub>out</sub></b> matrix (dim. resSize x outSize). Into the reservoir itself, one neuron is linked to every other : weights are saved in the <b style=\"color:#ffcc00\">W</b> matrix (dim. resSize x resSize).</p>\n",
        "\n",
        "<p style=\"text-align:justify\">Values of the reservoir's neurons are saved in a <b style=\"color:#ffcc00\">x</b> matrix (dim. resSize × 1). <b style=\"color:#00baff\">X</b> matrix contains bias (<b style=\"color:#99cc00\">1</b>), input (<b style=\"color:#99cc00\">u</b>) and reservoir's neurons (<b style=\"color:#ffcc00\">x</b>) values, over time (t). This matrix has a (1+inSize+resSize)×(trainLen-initLen) dimension. Finally, we save the ouput neuron values over time in a <b style=\"color:#ff0000\">y</b> matrix (dim. 1×(trainLen-initLen)).</p>\n",
        "\n",
        "<p style=\"text-align:justify\"><b style=\"color:#a7008a\">Y<sub>target</sub></b> matrix represents the « target » values. It matches the <b>data</b> values after initialization and training lengths. Those values will then be compared to the reservoir's output values.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCLXluX55m_J"
      },
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "\n",
        "    def __init__(self, trainLen=2000, testLen=2000, initLen=100) :\n",
        "        self.initLen = initLen\n",
        "        self.trainLen = trainLen\n",
        "        self.testLen = testLen\n",
        "        #self.data = np.loadtxt(\"MackeyGlass_t17.txt\")\n",
        "        data_df=pd.read_csv(\"ecg_1d_timeseries_prediction.csv\",sep=';')\n",
        "        self.data = data_df['ecg_value'].values\n",
        "        self.inSize = self.outSize = 1 #Input/Output dimensions\n",
        "        self.resSize = 300 #Reservoir size (prediction)\n",
        "        #self.resSize = 1000 #Reservoir size (generation)\n",
        "        self.a = 0.3 #Leak rate alpha\n",
        "        self.spectral_radius = 1.25 #Spectral raidus\n",
        "        self.input_scaling = 1. #Input scaling\n",
        "        self.reg =  1e-8 #None #Regularization factor - if None,\n",
        "        #we'd use pseudo-inverse rather than ridge regression\n",
        "\n",
        "        self.mode = 'prediction'\n",
        "        #self.mode = 'generative'\n",
        "\n",
        "        #Change the seed, reservoir performances should be averaged accross\n",
        "        #at least 20 random instances (with the same set of parameters)\n",
        "        seed = None #42\n",
        "\n",
        "        set_seed(seed)\n",
        "\n",
        "nw = Network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWMTq5C55m_J"
      },
      "source": [
        "## Dynamic plot of a data sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqo_55715m_K"
      },
      "source": [
        "We will now display a sample of data from the <i>data</i> file, by plotting the first 5,000 iterations. You can change the number of iterations by moving the cursor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMwsYSgk5m_K"
      },
      "outputs": [],
      "source": [
        "def plot_figure(f) :\n",
        "    plt.figure(0).clear()\n",
        "    plt.plot(nw.data[0:int(f)])\n",
        "    #plt.ylim([-1.1,1.1])\n",
        "    plt.title('A sample of input data')\n",
        "\n",
        "interact(plot_figure, f=FloatSlider(value=2000,min=1000,max=10000,step=1000,continuous_update=False,description='time steps'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqIWbEp65m_K"
      },
      "source": [
        "## Processing the network with the parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEsZb1qN5m_L"
      },
      "source": [
        "[link text](https://)We first randomly generate <b style=\"color:#99cc00\">W<sub>in</sub></b> input weights, and <b style=\"color:#ffcc00\">W</b> reservoir weights. Then, we create the matrices <b style=\"color:#ffcc00\">x</b>, <b style=\"color:#a7008a\">Y<sub>target</sub></b> and <b style=\"color:#00baff\">X</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9JjH1N425m_L"
      },
      "outputs": [],
      "source": [
        "def initialization(nw) :\n",
        "\n",
        "    #Weights\n",
        "    nw.Win = (np.random.rand(nw.resSize,1+nw.inSize)-0.5) * nw.input_scaling\n",
        "    nw.W = np.random.rand(nw.resSize,nw.resSize)-0.5\n",
        "\n",
        "    #Matrices\n",
        "    #Allocated memory for the design (collected states) matrix\n",
        "    nw.X = np.zeros((1+nw.inSize+nw.resSize,nw.trainLen-nw.initLen))\n",
        "    #Set the corresponding target matrix directly\n",
        "    nw.Ytarget = nw.data[None,nw.initLen+1:nw.trainLen+1]\n",
        "\n",
        "    #Run the reservoir with the data and collect X\n",
        "    nw.x = np.zeros((nw.resSize,1))\n",
        "\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP3mlpGT5m_L"
      },
      "source": [
        "We compute <b style=\"color:#ffcc00\">W</b> (reservoir weights) spectral radius (i.e., the biggest of the absolute eigenvalues). This number will then be used to scale the weights : the biggest the spectral radius is, the easiest it will be for the system to remember longer inputs.\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i7wNUj8U5m_L"
      },
      "outputs": [],
      "source": [
        "def compute_spectral_radius(nw):\n",
        "    print('Computing spectral radius...',end=\" \")\n",
        "    rhoW = max(abs(linalg.eig(nw.W)[0]))\n",
        "    print('Done.')\n",
        "    nw.W *= nw.spectral_radius / rhoW\n",
        "\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utvXe0_25m_M"
      },
      "source": [
        "<p style=\"text-align:justify\">We continue with a training phase, which duration depends of the <b>trainLen</b> value. Data from the <i>data</i> file are used in input. The algorithm changes every reservoir neuron value on every step, depending on the <b style=\"color:#99cc00\">W<sub>in</sub></b>. weights, using the following formula :</p></br></br>\n",
        "\n",
        "\n",
        "$$x_{n} = (1-\\alpha)x_{n-1} \\times \\alpha \\tanh(W_{in}.u_{n-1}) + W.x_{n-1}$$\n",
        "\n",
        "\n",
        "<p style=\"text-align:justify\">In this formula, the $\\alpha$ acts as a \"memory\" factor for the network.\n",
        "Once the initialization span (<b>initLen</b>) is over, the algorithm begins to modify the X matrix, which collects neurons states during the simulation : the first neuron is the bias (1), the second one is the input, and every other are the x matrix :</p>\n",
        "$$X_{n} = [1;u_{n};x_{n}]$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tA4c-aqv5m_M"
      },
      "outputs": [],
      "source": [
        "def learning_phase(nw) :\n",
        "    for t in range(nw.trainLen):\n",
        "        #Input data\n",
        "        nw.u = nw.data[t]\n",
        "        nw.x = (1-nw.a)*nw.x + nw.a*np.tanh( np.dot(nw.Win, np.vstack((1,nw.u)) ) + np.dot( nw.W, nw.x ) )\n",
        "        #After the initialization, we start modifying X\n",
        "        if t >= nw.initLen:\n",
        "            nw.X[:,t-nw.initLen] = np.vstack((1,nw.u,nw.x))[:,0]\n",
        "\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wslMcdM5m_M"
      },
      "source": [
        "Now, we record output weights <b style=\"color:#ff0000\">W<sub>out</sub></b>, and we correct those according to the reservoir's neurons values (<b style=\"color:#00baff\">X</b>) and the target values (<b style=\"color:#a7008a\">Y<sub>target</sub></b>) :\n",
        "\n",
        "\n",
        "$$W_{out} = (Y_{t}.X^{T}).(X.X^{T} + reg.I)^{-1}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wF39YKrN5m_N"
      },
      "outputs": [],
      "source": [
        "def train_output(nw) :\n",
        "    nw.X_T = nw.X.T\n",
        "    if nw.reg is not None:\n",
        "        # Ridge regression (linear regression with regularization)\n",
        "        nw.Wout = np.dot(np.dot(nw.Ytarget,nw.X_T), linalg.inv(np.dot(nw.X,nw.X_T) + \\\n",
        "            nw.reg*np.eye(1+nw.inSize+nw.resSize) ) )\n",
        "    else:\n",
        "        # Pseudo-inverse\n",
        "        nw.Wout = np.dot(nw.Ytarget, linalg.pinv(nw.X) )\n",
        "\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KXXV-TI5m_N"
      },
      "source": [
        "When the training is over, we launch network testing. In generative mode, at each iteration, we will use the output to generate the next one. In predictive mode, we will use the real data to try to generate the next one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QkknMcBo5m_N"
      },
      "outputs": [],
      "source": [
        "def test(nw) :\n",
        "    #Run the trained ESN in a generative mode. no need to initialize here,\n",
        "    #because x is initialized with training data and we continue from there.\n",
        "    nw.Y = np.zeros((nw.outSize,nw.testLen))\n",
        "    nw.u = nw.data[nw.trainLen]\n",
        "    for t in range(nw.testLen):\n",
        "        nw.x = (1-nw.a)*nw.x + nw.a*np.tanh( np.dot(nw.Win, np.vstack((1,nw.u)) ) + np.dot(nw.W,nw.x ) )\n",
        "        nw.y = np.dot(nw.Wout, np.vstack((1,nw.u,nw.x)) )\n",
        "        nw.Y[:,t] = nw.y\n",
        "        if nw.mode == 'generative':\n",
        "            #Generative mode:\n",
        "            nw.u = nw.y\n",
        "        elif nw.mode == 'prediction':\n",
        "            #Predictive mode:\n",
        "            nw.u = nw.data[nw.trainLen+t+1]\n",
        "        else:\n",
        "            raise(Exception, \"ERROR: 'mode' was not set correctly.\")\n",
        "\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Otw_tml_5m_N"
      },
      "outputs": [],
      "source": [
        "def compute_error(nw) :\n",
        "    # Computing MSE for the first errorLen iterations\n",
        "    errorLen = 500\n",
        "    mse = sum( np.square( nw.data[nw.trainLen+1:nw.trainLen+errorLen+1] - nw.Y[0,0:errorLen] ) ) / errorLen\n",
        "    print('MSE = ' + str( mse ))\n",
        "\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lss8-vla5m_N"
      },
      "outputs": [],
      "source": [
        "def compute_network(nw) :\n",
        "    nw = initialization(nw)\n",
        "    nw = compute_spectral_radius(nw)\n",
        "    nw = learning_phase(nw)\n",
        "    nw = train_output(nw)\n",
        "    nw = test(nw)\n",
        "    nw = compute_error(nw)\n",
        "    return(nw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi797bQJ5m_N"
      },
      "source": [
        "## Definition of the network parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc72xxGp5m_N"
      },
      "source": [
        "Here, you can modify the network parameters by moving the cursors, then pressing Validate. This will affect every subsequent graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dORuv-K35m_N"
      },
      "outputs": [],
      "source": [
        "select_mode = ToggleButtons(description='Mode:',\n",
        "    options=['prediction', 'generative'])\n",
        "var1 = FloatSlider(value=300, min=0, max=1000, step=1, description='resSize')\n",
        "var2 = FloatSlider(value=100, min=0, max=2000, step=1, description='initLen')\n",
        "var3 = FloatSlider(value=2000, min=0, max=5000, step=1, description='trainLen')\n",
        "var4 = FloatSlider(value=2000, min=0, max=5000, step=1, description='testLen')\n",
        "var5 = FloatSlider(value=1.25, min=0, max=10, step=0.05, description='spectral radius')\n",
        "var6 = FloatSlider(value=0.3, min=0, max=1, step=0.01, description='leak rate')\n",
        "valid = Button(description='Validate')\n",
        "\n",
        "def record_values(_) :\n",
        "    clear_output()\n",
        "    nw.mode=select_mode.value\n",
        "    nw.resSize=int(var1.value)\n",
        "    nw.initLen=int(var2.value)\n",
        "    nw.trainLen=int(var3.value)\n",
        "    nw.testLen=int(var4.value)\n",
        "    nw.spectral_radius=float(var5.value)\n",
        "    nw.a=float(var6.value)\n",
        "    print(\"InitLen:\", nw.initLen, \"TrainLen:\", nw.trainLen, \"TestLen:\", nw.testLen)\n",
        "    print(\"ResSize:\", nw.resSize, \"Spectral Radius:\", nw.spectral_radius, \"Leak Rate:\", nw.a)\n",
        "    compute_network(nw)\n",
        "    return(nw)\n",
        "\n",
        "display(select_mode)\n",
        "display(var1)\n",
        "display(var2)\n",
        "display(var3)\n",
        "display(var4)\n",
        "display(var5)\n",
        "display(var6)\n",
        "display(valid)\n",
        "\n",
        "valid.on_click(record_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(valid)"
      ],
      "metadata": {
        "id": "VDFHqGK8tWoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_values(_)"
      ],
      "metadata": {
        "id": "_6Z8DchCrVfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdh97kpY5m_O"
      },
      "source": [
        "## Graph 1: Comparison between expected and estimated outputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nw.Y"
      ],
      "metadata": {
        "id": "CQhE3jdaiRiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErSDzxNP5m_O"
      },
      "outputs": [],
      "source": [
        "var7 = FloatSlider(value=2000,min=10,max=10000,step=10,description='time steps')\n",
        "valid = Button(description='Validate')\n",
        "\n",
        "def trace_graph1(_) :\n",
        "    clear_output()\n",
        "    f=int(var7.value)\n",
        "    plt.figure(1).clear()\n",
        "    plt.plot( nw.data[nw.trainLen+1:nw.trainLen+f+1], 'g' )\n",
        "    plt.plot( nw.Y.T[0:f], 'b' )\n",
        "    plt.title('Target and generated signals $y(n)$ starting at $n=0$')\n",
        "    if nw.mode == 'generative':\n",
        "        plt.legend(['Target signal', 'Free-running predicted signal'])\n",
        "    elif nw.mode == 'prediction':\n",
        "        plt.legend(['Target signal', 'Predicted signal'])\n",
        "\n",
        "valid.on_click(trace_graph1)\n",
        "\n",
        "display(var7)\n",
        "display(valid)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trace_graph1(_)"
      ],
      "metadata": {
        "id": "Yo5K54jJiDUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hI5W_1Y5m_O"
      },
      "source": [
        "## Graph 2: Difference between expected and estimated outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYyC2dzS5m_O"
      },
      "outputs": [],
      "source": [
        "var8 = FloatSlider(value=2000,min=10,max=nw.testLen,step=10,description='time steps')\n",
        "var9 = FloatSlider(value=0.2,min=0.001,max=10,step=0.001,description='amplitude')\n",
        "valid = Button(description='Validate')\n",
        "\n",
        "def trace_graph2(_) :\n",
        "    clear_output()\n",
        "    f=int(var8.value)\n",
        "    amp=float(var9.value)\n",
        "    plt.figure(2).clear()\n",
        "    plt.ylim([-amp,amp])\n",
        "    plt.plot(nw.data[nw.trainLen+1:nw.trainLen+f+1]-nw.Y[0][0:f], 'g' )\n",
        "    print(nw.Y[0].shape)\n",
        "    plt.title('Target and predicted signal difference through time')\n",
        "    if nw.mode == 'generative':\n",
        "        plt.legend(['Target signal', 'Free-running predicted signal'])\n",
        "    elif nw.mode == 'prediction':\n",
        "        plt.legend(['Target signal', 'Predicted signal'])\n",
        "\n",
        "valid.on_click(trace_graph2)\n",
        "\n",
        "display(var8)\n",
        "display(var9)\n",
        "display(valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G1rRbVe5m_O"
      },
      "source": [
        "## Graph 3: Plotting neurons activations (total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XocGMnSD5m_O"
      },
      "outputs": [],
      "source": [
        "var10 = FloatSlider(value=2000,min=10,max=nw.trainLen-nw.initLen,step=10,description='time steps')\n",
        "var11 = FloatSlider(value=10, min=1, max=nw.resSize, step=1, description='number of neurons')\n",
        "valid = Button(description='Validate')\n",
        "\n",
        "def trace_graph3(_) :\n",
        "    clear_output()\n",
        "    f=int(var10.value)\n",
        "    nb=int(var11.value)\n",
        "    plt.figure(3).clear()\n",
        "    plt.plot( nw.X[2:2+nb,0:f].T )\n",
        "    print(nw.X.shape)\n",
        "    plt.ylim([-1.1,1.1])\n",
        "    plt.title('Activations $\\mathbf{x}(n)$ from Reservoir Neurons ID 0 to '+str(nb-1)+' for '+str(f)+' time steps')\n",
        "\n",
        "valid.on_click(trace_graph3)\n",
        "\n",
        "display(var10)\n",
        "display(var11)\n",
        "display(valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt6ixqSd5m_P"
      },
      "source": [
        "## Graph 4: Plotting single neuron activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFCuaKo05m_P"
      },
      "outputs": [],
      "source": [
        "var12 = FloatSlider(value=2000,min=10,max=nw.trainLen-nw.initLen,step=10,description='time steps')\n",
        "var13 = FloatSlider(value=2, min=0, max=nw.resSize-1, step=1, description='neuron ID')\n",
        "valid = Button(description='Validate')\n",
        "\n",
        "def trace_graph4(_) :\n",
        "    clear_output()\n",
        "    f=int(var12.value)\n",
        "    num=int(var13.value)\n",
        "    plt.figure(4).clear()\n",
        "    plt.plot( nw.X[2+num,:f].T )\n",
        "    plt.ylim([-1.1,1.1])\n",
        "    plt.title('Activations $\\mathbf{x}(n)$ from Reservoir Neuron ID '+str(num)+' for '+str(f)+' time steps')\n",
        "\n",
        "valid.on_click(trace_graph4)\n",
        "\n",
        "display(var12)\n",
        "display(var13)\n",
        "display(valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d7OMSqy5m_P"
      },
      "source": [
        "## Graph 5: Output weights at the end of the simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfKzyNzD5m_P"
      },
      "outputs": [],
      "source": [
        "valid = Button(description='Show')\n",
        "\n",
        "def trace_graph5(_) :\n",
        "    clear_output()\n",
        "    plt.figure(5).clear()\n",
        "    plt.bar( range(1+nw.inSize+nw.resSize), nw.Wout.T )\n",
        "    plt.title('Output weights $\\mathbf{W}^{out}$')\n",
        "\n",
        "valid.on_click(trace_graph5)\n",
        "\n",
        "display(valid)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}