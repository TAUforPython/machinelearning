{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVoHCltNFW4A8rzzvktAel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAUforPython/machinelearning/blob/main/NN_arrhythmia_ECG_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arrhythmia on ECG Classification using CNN\n",
        "\n",
        "Источник данных:\n",
        "https://physionet.org/content/mitdb/1.0.0/mitdbdir/src/#files-panel\n"
      ],
      "metadata": {
        "id": "dpziyuly2jrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Samples: 109446\n",
        "Number of Categories: 5\n",
        "Sampling Frequency: 125Hz\n",
        "Data Source: Physionet's MIT-BIH Arrhythmia Dataset\n",
        "Classes: ['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4]\n",
        "\n",
        "-N : Non-ecotic beats (normal beat)\n",
        "-S : Supraventricular ectopic beats\n",
        "-V : Ventricular ectopic beats\n",
        "-F : Fusion Beats\n",
        "-Q : Unknown Beats"
      ],
      "metadata": {
        "id": "0DMXp6TV-Qu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/gregoiredc/arrhythmia-on-ecg-classification-using-cnn/notebook"
      ],
      "metadata": {
        "id": "kSPeVZcb-d_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeHfhm903Bse",
        "outputId": "b35f15a8-7f03-488b-a636-39e993cb9b8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dPqTZi7d0hfR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import class_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "m5ac46wE3NZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv',header=None)\n",
        "test_df=pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv',header=None)"
      ],
      "metadata": {
        "id": "7PUlgbAL3QQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[187]=train_df[187].astype(int)\n",
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "metadata": {
        "id": "RlaHlD5L896i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
        "plt.pie(equilibre, labels=['n','q','v','s','f'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WdRfO4sY8-tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "df_1=train_df[train_df[187]==1]\n",
        "df_2=train_df[train_df[187]==2]\n",
        "df_3=train_df[train_df[187]==3]\n",
        "df_4=train_df[train_df[187]==4]\n",
        "df_0=(train_df[train_df[187]==0]).sample(n=20000,random_state=42)\n",
        "\n",
        "df_1_upsample=resample(df_1,replace=True,n_samples=20000,random_state=123)\n",
        "df_2_upsample=resample(df_2,replace=True,n_samples=20000,random_state=124)\n",
        "df_3_upsample=resample(df_3,replace=True,n_samples=20000,random_state=125)\n",
        "df_4_upsample=resample(df_4,replace=True,n_samples=20000,random_state=126)\n",
        "\n",
        "train_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "DtAI8EBb9BR0",
        "outputId": "2fa9f223-9837-4d4e-c76c-d7637fe8ee68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ad691697c827>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m187\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m187\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m187\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m187\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "equilibre=train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "metadata": {
        "id": "BP8_3ytl9HYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=train_df.groupby(187,group_keys=False).apply(lambda train_df : train_df.sample(1))"
      ],
      "metadata": {
        "id": "WnSkyEqZ9OEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " plt.plot(c.iloc[0,:186])"
      ],
      "metadata": {
        "id": "m4z4vuTA9Z4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_train=train_df[187]\n",
        "target_test=test_df[187]\n",
        "y_train=to_categorical(target_train)\n",
        "y_test=to_categorical(target_test)"
      ],
      "metadata": {
        "id": "l14Zm_r_9chE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# что-то надо сделать с нулями в выборке!!!!!!!\n",
        "X_train=train_df.iloc[:,:186].values\n",
        "X_test=test_df.iloc[:,:186].values"
      ],
      "metadata": {
        "id": "1li9GLrZ9x4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def network(X_train,y_train,X_test,y_test):\n",
        "\n",
        "\n",
        "    im_shape=(X_train.shape[1],1)\n",
        "    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n",
        "    conv1_1=Convolution1D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)\n",
        "    conv1_1=BatchNormalization()(conv1_1)\n",
        "    pool1=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(conv1_1)\n",
        "    conv2_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)\n",
        "    conv2_1=BatchNormalization()(conv2_1)\n",
        "    pool2=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n",
        "    conv3_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)\n",
        "    conv3_1=BatchNormalization()(conv3_1)\n",
        "    pool3=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n",
        "    flatten=Flatten()(pool3)\n",
        "    dense_end1 = Dense(64, activation='relu')(flatten)\n",
        "    dense_end2 = Dense(32, activation='relu')(dense_end1)\n",
        "    main_output = Dense(5, activation='softmax', name='main_output')(dense_end2)\n",
        "\n",
        "\n",
        "    model = Model(inputs= inputs_cnn, outputs=main_output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
        "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "    history=model.fit(X_train, y_train,epochs=40,callbacks=callbacks, batch_size=32,validation_data=(X_test,y_test))\n",
        "    model.load_weights('best_model.h5')\n",
        "    return(model,history)"
      ],
      "metadata": {
        "id": "Fh4au0vi97Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(history,X_test,y_test,model):\n",
        "    scores = model.evaluate((X_test),y_test, verbose=0)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "    print(history)\n",
        "    fig1, ax_acc = plt.subplots()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model - Accuracy')\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    fig2, ax_loss = plt.subplots()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Model- Loss')\n",
        "    plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.show()\n",
        "    target_names=['0','1','2','3','4']\n",
        "\n",
        "    y_true=[]\n",
        "    for element in y_test:\n",
        "        y_true.append(np.argmax(element))\n",
        "    prediction_proba=model.predict(X_test)\n",
        "    prediction=np.argmax(prediction_proba,axis=1)\n",
        "    cnf_matrix = confusion_matrix(y_true, prediction)"
      ],
      "metadata": {
        "id": "E9JrDuKO9_Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model,history=network(X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "id": "R931EX_0-B8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(history,X_test,y_test,model)\n",
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "id": "_2frePyK-EGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],normalize=True,\n",
        "                      title='Confusion matrix, with normalization')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1wG_mYNq-GnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVKR2vA5-KPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}